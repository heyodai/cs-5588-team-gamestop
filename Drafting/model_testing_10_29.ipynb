{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install ta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QKY39lSO1Ma",
        "outputId": "43b0b97d-5a95-4d2e-9b8b-863cc6932454"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.10/dist-packages (0.11.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from ta) (1.26.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from ta) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->ta) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->ta) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestRegressor, StackingRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from xgboost import XGBRegressor"
      ],
      "metadata": {
        "id": "jqapd35NLbfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "czmwneobLVuN",
        "outputId": "a1162ed3-5867-4985-844a-72d73557563a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression RMSE: 1.2339620038797294\n",
            "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Random Forest Params: {'bootstrap': True, 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Random Forest RMSE: 11.660958758374814\n",
            "XGBoost RMSE: 12.352171478526191\n",
            "Stacking Regressor RMSE: 10.615222904839735\n",
            "ARIMA RMSE: 17.34316360947922\n"
          ]
        }
      ],
      "source": [
        "# Fetch stock data using yfinance\n",
        "def fetch_data(ticker, start_date, end_date):\n",
        "    data = yf.download(ticker, start=start_date, end=end_date)\n",
        "    return data\n",
        "\n",
        "# Create features manually without using the `ta` library\n",
        "def create_features(data):\n",
        "    # Moving Averages\n",
        "    data['MA5'] = data['Close'].rolling(window=5).mean().shift(1)\n",
        "    data['MA10'] = data['Close'].rolling(window=10).mean().shift(1)\n",
        "    data['MA20'] = data['Close'].rolling(window=20).mean().shift(1)\n",
        "    data['MA50'] = data['Close'].rolling(window=50).mean().shift(1)\n",
        "\n",
        "    # Momentum and Volatility\n",
        "    data['Momentum'] = data['Close'] - data['Close'].shift(1)\n",
        "    data['Volatility'] = data['Close'].pct_change().rolling(window=20).std().shift(1)\n",
        "\n",
        "    # MACD\n",
        "    data['EMA12'] = data['Close'].ewm(span=12, adjust=False).mean()\n",
        "    data['EMA26'] = data['Close'].ewm(span=26, adjust=False).mean()\n",
        "    data['MACD'] = data['EMA12'] - data['EMA26']\n",
        "\n",
        "    # Lagged Values\n",
        "    for lag in range(1, 6):\n",
        "        data[f'Close_Lag{lag}'] = data['Close'].shift(lag)\n",
        "\n",
        "    # Rolling mean, max, and Bollinger Bands\n",
        "    data['Rolling_Mean_7'] = data['Close'].rolling(window=7).mean()\n",
        "    data['Rolling_Max_7'] = data['Close'].rolling(window=7).max()\n",
        "    data['Upper_Bollinger'] = data['Rolling_Mean_7'] + 2 * data['Volatility']\n",
        "    data['Lower_Bollinger'] = data['Rolling_Mean_7'] - 2 * data['Volatility']\n",
        "\n",
        "    data = data.dropna()\n",
        "    return data\n",
        "\n",
        "# Prepare data for model\n",
        "def prepare_data(data):\n",
        "    features = [\n",
        "        'MA5', 'MA10', 'MA20', 'MA50', 'Momentum', 'Volatility', 'MACD',\n",
        "        'Rolling_Mean_7', 'Rolling_Max_7', 'Upper_Bollinger', 'Lower_Bollinger'\n",
        "    ] + [f'Close_Lag{lag}' for lag in range(1, 6)]\n",
        "\n",
        "    X = data[features]\n",
        "    y = data['Close'].values.ravel()\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    tscv = TimeSeriesSplit(n_splits=5)\n",
        "    return X_scaled, y, tscv, scaler\n",
        "\n",
        "# Model evaluation\n",
        "def evaluate_model(X, y, model, tscv):\n",
        "    rmses = []\n",
        "    for train_index, test_index in tscv.split(X):\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        rmses.append(rmse)\n",
        "\n",
        "    return np.mean(rmses)\n",
        "\n",
        "# Hyperparameter tuning for Random Forest\n",
        "def tune_random_forest(X, y, tscv):\n",
        "    param_grid = {\n",
        "        'n_estimators': [100, 200, 500],\n",
        "        'max_depth': [10, 20, 30, None],\n",
        "        'min_samples_split': [2, 5, 10],\n",
        "        'min_samples_leaf': [1, 2, 4],\n",
        "        'bootstrap': [True, False]\n",
        "    }\n",
        "    rf = RandomForestRegressor(random_state=42)\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=tscv, n_jobs=-1, verbose=2)\n",
        "    grid_search.fit(X, y)\n",
        "    print(f\"Best Random Forest Params: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Hyperparameter tuning for SVM\n",
        "def tune_svm(X, y, tscv):\n",
        "    param_grid = {\n",
        "        'C': [0.1, 1, 10],\n",
        "        'gamma': ['scale', 'auto'],\n",
        "        'kernel': ['linear', 'rbf', 'poly']\n",
        "    }\n",
        "    svm = SVR()\n",
        "    grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=tscv, n_jobs=-1, verbose=2)\n",
        "    grid_search.fit(X, y)\n",
        "    print(f\"Best SVM Params: {grid_search.best_params_}\")\n",
        "    return grid_search.best_estimator_\n",
        "\n",
        "# Evaluate ARIMA model\n",
        "def evaluate_arima_model(y, tscv):\n",
        "    rmses = []\n",
        "    for train_index, test_index in tscv.split(y):\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "        arima_model = ARIMA(y_train, order=(5, 1, 0))  # Adjust based on analysis\n",
        "        arima_fit = arima_model.fit()\n",
        "\n",
        "        y_pred = arima_fit.forecast(steps=len(y_test))\n",
        "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        rmses.append(rmse)\n",
        "\n",
        "    return np.mean(rmses)\n",
        "\n",
        "# Main function to fetch data, generate features, and evaluate models\n",
        "def main(ticker, start_date, end_date):\n",
        "    data = fetch_data(ticker, start_date, end_date)\n",
        "    data = create_features(data)\n",
        "    X_scaled, y, tscv, scaler = prepare_data(data)\n",
        "\n",
        "    # Linear Regression (Baseline)\n",
        "    lr_model = Ridge()\n",
        "    print(f\"Linear Regression RMSE: {evaluate_model(X_scaled, y, lr_model, tscv)}\")\n",
        "\n",
        "    # Random Forest with Hyperparameter Tuning\n",
        "    rf_model = tune_random_forest(X_scaled, y, tscv)\n",
        "    print(f\"Random Forest RMSE: {evaluate_model(X_scaled, y, rf_model, tscv)}\")\n",
        "\n",
        "    # XGBoost Regressor\n",
        "    xgb_model = XGBRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
        "    print(f\"XGBoost RMSE: {evaluate_model(X_scaled, y, xgb_model, tscv)}\")\n",
        "\n",
        "    # SVM with Hyperparameter Tuning\n",
        "    svm_model = tune_svm(X_scaled, y, tscv)\n",
        "    print(f\"SVM RMSE: {evaluate_model(X_scaled, y, svm_model, tscv)}\")\n",
        "\n",
        "    # Stacking Regressor\n",
        "    stacking_model = StackingRegressor(\n",
        "        estimators=[('rf', rf_model), ('xgb', xgb_model), ('svm', svm_model)],\n",
        "        final_estimator=GradientBoostingRegressor()\n",
        "    )\n",
        "    print(f\"Stacking Regressor RMSE: {evaluate_model(X_scaled, y, stacking_model, tscv)}\")\n",
        "\n",
        "    # ARIMA Model\n",
        "    arima_rmse = evaluate_arima_model(y, tscv)\n",
        "    print(f\"ARIMA RMSE: {arima_rmse}\")\n",
        "\n",
        "# Run the code\n",
        "if __name__ == \"__main__\":\n",
        "    ticker = \"AAPL\"\n",
        "    start_date = \"2018-01-01\"\n",
        "    end_date = \"2021-12-31\"\n",
        "    main(ticker, start_date, end_date)\n"
      ]
    }
  ]
}